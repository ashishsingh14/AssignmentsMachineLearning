{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import codecs\n",
    "import re\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from word2vecUtils import utils\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./Data/data_segments2.json\"\n",
    "data = open(filename).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = re.compile(r'{[\\n\\s]*\"_id\"[a-zA-Z0-9~`!@#$%^&*()\\-_+={}\\[\\]:;\\\"\\'<>,.?/|\\\\]*')\n",
    "#arr = pattern.findall(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_multiple(segments):\n",
    "    chunk = \"\"\n",
    "    for segment in segments:\n",
    "        chunk += segment\n",
    "        try:\n",
    "            yield json.loads(chunk)\n",
    "            chunk = \"\"\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(filename) as f:\n",
    "    for parsed_json in load_json_multiple(f):\n",
    "        data.append(parsed_json)\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "for i in xrange(len(data)):\n",
    "    for j in data[i][\"transcription_merged\"]:\n",
    "        temp = j\n",
    "        temp[\"_id\"] = data[i][\"_id\"]\n",
    "        data1.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>conv_no</th>\n",
       "      <th>end_time</th>\n",
       "      <th>line</th>\n",
       "      <th>question</th>\n",
       "      <th>segment</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>at indian east india company now by the way wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>HMM.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prospect</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>so you're creating tons of synonyms on the bac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rep</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>it is manual.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prospect</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53</td>\n",
       "      <td>right exactly you got it then next comes is th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rep</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id  conv_no end_time  \\\n",
       "0  d7da99f7-013b-4d63-84d9-421226ee5249      0.0       30   \n",
       "1  d7da99f7-013b-4d63-84d9-421226ee5249      1.0       31   \n",
       "2  d7da99f7-013b-4d63-84d9-421226ee5249      2.0       34   \n",
       "3  d7da99f7-013b-4d63-84d9-421226ee5249      3.0       35   \n",
       "4  d7da99f7-013b-4d63-84d9-421226ee5249      4.0       53   \n",
       "\n",
       "                                                line question segment  \\\n",
       "0  at indian east india company now by the way wh...      NaN     NaN   \n",
       "1                                               HMM.      NaN     NaN   \n",
       "2  so you're creating tons of synonyms on the bac...      NaN     NaN   \n",
       "3                                      it is manual.      NaN     NaN   \n",
       "4  right exactly you got it then next comes is th...      NaN     NaN   \n",
       "\n",
       "    speaker start_time  \n",
       "0       Rep          0  \n",
       "1  Prospect         30  \n",
       "2       Rep         31  \n",
       "3  Prospect         34  \n",
       "4       Rep         35  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2390, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.segment==\"None\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4612, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.segment.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                           2390\n",
       "Rep questions                   663\n",
       "Customer questions              523\n",
       "Next steps and action items     228\n",
       "Client reference                198\n",
       "Pricing                         114\n",
       "Pitch                           110\n",
       "Agenda                           89\n",
       "Customer pain points             88\n",
       "Objection                        65\n",
       "Competitor differentiation       46\n",
       "Relevant case study              32\n",
       "Brilio pitch                     32\n",
       "Competitor                       16\n",
       "Closing discussion               13\n",
       "Next steps                        2\n",
       "Unbxd pitch                       2\n",
       "WebEngage pitch                   1\n",
       "Name: segment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.segment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the records for which segment column is not null"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The total records are 4612, out of this only 228 contains the value \"Next steps and action items\". So our target label will become 1 as \"Next steps and action items\" and 0 as \"others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[~df.segment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>conv_no</th>\n",
       "      <th>end_time</th>\n",
       "      <th>line</th>\n",
       "      <th>question</th>\n",
       "      <th>segment</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>11.0</td>\n",
       "      <td>245</td>\n",
       "      <td>the next piece what I really wanted to also hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pitch</td>\n",
       "      <td>Rep</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>17.0</td>\n",
       "      <td>303</td>\n",
       "      <td>however what Celeb rose is not very good at is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Competitor differentiation</td>\n",
       "      <td>Rep</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>19.0</td>\n",
       "      <td>364</td>\n",
       "      <td>yes yes that is interesting to me now one one ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer pain points</td>\n",
       "      <td>Prospect</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>21.0</td>\n",
       "      <td>407</td>\n",
       "      <td>so we have and I did this for a couple of reas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer pain points</td>\n",
       "      <td>Prospect</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>d7da99f7-013b-4d63-84d9-421226ee5249</td>\n",
       "      <td>24.0</td>\n",
       "      <td>429</td>\n",
       "      <td>you guys offer a link search in navigation.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer questions</td>\n",
       "      <td>Prospect</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     _id  conv_no end_time  \\\n",
       "11  d7da99f7-013b-4d63-84d9-421226ee5249     11.0      245   \n",
       "17  d7da99f7-013b-4d63-84d9-421226ee5249     17.0      303   \n",
       "19  d7da99f7-013b-4d63-84d9-421226ee5249     19.0      364   \n",
       "21  d7da99f7-013b-4d63-84d9-421226ee5249     21.0      407   \n",
       "24  d7da99f7-013b-4d63-84d9-421226ee5249     24.0      429   \n",
       "\n",
       "                                                 line question  \\\n",
       "11  the next piece what I really wanted to also hi...      NaN   \n",
       "17  however what Celeb rose is not very good at is...      NaN   \n",
       "19  yes yes that is interesting to me now one one ...      NaN   \n",
       "21  so we have and I did this for a couple of reas...      NaN   \n",
       "24        you guys offer a link search in navigation.      NaN   \n",
       "\n",
       "                       segment   speaker start_time  \n",
       "11                       Pitch       Rep         87  \n",
       "17  Competitor differentiation       Rep        260  \n",
       "19        Customer pain points  Prospect        318  \n",
       "21        Customer pain points  Prospect        365  \n",
       "24          Customer questions  Prospect        426  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"target\"] = np.where(df1[\"segment\"]==\"Next steps and action items\",1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.end_time = df1.end_time.astype(np.float64)\n",
    "df1.start_time = df1.start_time.astype(np.float64)\n",
    "df1.conv_no = df1.conv_no.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index(np.arange(len(df1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"time_difference\"] = df1[\"end_time\"] - df1[\"start_time\"]\n",
    "df1[\"time_difference\"] = df1[\"time_difference\"]/max(df1[\"time_difference\"])\n",
    "df1[\"conv_no\"] = df1[\"conv_no\"] / max(df1[\"conv_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rep         2818\n",
       "Prospect    1794\n",
       "Name: speaker, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df1[\"speaker\"] = le.fit_transform(df1[\"speaker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop([\"_id\",\"question\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data for unuwanter characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: re.sub(r\"[^\\x00-\\x7f]\",\" \",x))\n",
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: re.sub(r\"^[a-zA-Z0-9\\s]\", \"\", x))\n",
    "df1[\"line\"] = df1[\"line\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: re.sub(r\"[\\s]+\",\" \", x).strip())\n",
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['compoundScore'] = df1['line'].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "df1['negSent'] = df1['line'].apply(lambda x: analyzer.polarity_scores(x)[\"neg\"])\n",
    "df1['posSent'] = df1['line'].apply(lambda x: analyzer.polarity_scores(x)[\"pos\"])\n",
    "df1['neuSent'] = df1['line'].apply(lambda x: analyzer.polarity_scores(x)[\"neu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: \" \".join([i for i in word_tokenize(x) if i not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: \" \".join([stemmer.stem(i) for i in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"line\"] = df1[\"line\"].apply(lambda x: \" \".join([i for i in word_tokenize(x) if len(x)>2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_no</th>\n",
       "      <th>end_time</th>\n",
       "      <th>line</th>\n",
       "      <th>segment</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_time</th>\n",
       "      <th>target</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>compoundScore</th>\n",
       "      <th>negSent</th>\n",
       "      <th>posSent</th>\n",
       "      <th>neuSent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029650</td>\n",
       "      <td>245.0</td>\n",
       "      <td>next piec realli want also highlight coupl thi...</td>\n",
       "      <td>Pitch</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335456</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045822</td>\n",
       "      <td>303.0</td>\n",
       "      <td>owev celeb rose good &lt; &gt; spellcheck n't know g...</td>\n",
       "      <td>Competitor differentiation</td>\n",
       "      <td>1</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091295</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051213</td>\n",
       "      <td>364.0</td>\n",
       "      <td>es yes interest one one one question thing wan...</td>\n",
       "      <td>Customer pain points</td>\n",
       "      <td>0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097665</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056604</td>\n",
       "      <td>407.0</td>\n",
       "      <td>coupl reason one well first thing get influenc...</td>\n",
       "      <td>Customer pain points</td>\n",
       "      <td>0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089172</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064690</td>\n",
       "      <td>429.0</td>\n",
       "      <td>ou guy offer link search navig .</td>\n",
       "      <td>Customer questions</td>\n",
       "      <td>0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conv_no  end_time                                               line  \\\n",
       "0  0.029650     245.0  next piec realli want also highlight coupl thi...   \n",
       "1  0.045822     303.0  owev celeb rose good < > spellcheck n't know g...   \n",
       "2  0.051213     364.0  es yes interest one one one question thing wan...   \n",
       "3  0.056604     407.0  coupl reason one well first thing get influenc...   \n",
       "4  0.064690     429.0                   ou guy offer link search navig .   \n",
       "\n",
       "                      segment  speaker  start_time  target  time_difference  \\\n",
       "0                       Pitch        1        87.0       0         0.335456   \n",
       "1  Competitor differentiation        1       260.0       0         0.091295   \n",
       "2        Customer pain points        0       318.0       0         0.097665   \n",
       "3        Customer pain points        0       365.0       0         0.089172   \n",
       "4          Customer questions        0       426.0       0         0.006369   \n",
       "\n",
       "   compoundScore  negSent  posSent  neuSent  \n",
       "0         0.9971    0.018    0.204    0.778  \n",
       "1         0.7039    0.018    0.077    0.905  \n",
       "2         0.9509    0.000    0.163    0.837  \n",
       "3         0.2500    0.032    0.053    0.915  \n",
       "4         0.0000    0.000    0.000    1.000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"predicted_value\"] = np.where(df1[\"segment\"]==\"Next steps and action items\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "        words = review_text.lower().split()\n",
    "        if remove_stopwords:\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "            words = [w for w in words if not w in stops]\n",
    "        return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc = []\n",
    "for index, row in df1.iterrows():\n",
    "    clean_desc.append(\" \".join(\n",
    "        review_to_wordlist(row[\"line\"], False)))\n",
    "\n",
    "#vectorizer = CountVectorizer(max_features=5000)\n",
    "#data_features = vectorizer.fit_transform(clean_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the TFID for the column \"line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vectorizer = TfidfVectorizer()\n",
    "data_features = tfid_vectorizer.fit_transform(clean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(data_features)\n",
    "data_features = data_features.astype(np.float32)\n",
    "features_df = pd.DataFrame(data_features.todense(), columns=tfid_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4612, 4630)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df1, features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.drop([\"start_time\",\"end_time\",\"line\",\"segment\",\"target\",\"conv_no\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_combined.sample(frac=0.7,random_state=777)\n",
    "test = df_combined.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"./train_sample.csv\")\n",
    "#test = pd.read_csv(\"./test_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"predicted_value\"]\n",
    "y_test = test[\"predicted_value\"]\n",
    "X_train = train.drop([\"predicted_value\"],axis=1)\n",
    "X_test = test.drop([\"predicted_value\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3228, 4633), (3228,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "# train.to_csv(\"./train_sample.csv\",index=False)\n",
    "# test.to_csv(\"./test_sample.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train.as_matrix()\n",
    "y_test = y_test.as_matrix()\n",
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'C',\n",
       " 'verbose',\n",
       " 'intercept_scaling',\n",
       " 'fit_intercept',\n",
       " 'max_iter',\n",
       " 'penalty',\n",
       " 'multi_class',\n",
       " 'random_state',\n",
       " 'dual',\n",
       " 'tol',\n",
       " 'class_weight']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model,X_train,y_train,X_test,y_test,testing=True):\n",
    "    model.fit(X_train,y_train)\n",
    "    if testing:\n",
    "        y_pred = model.predict(X_test)\n",
    "        print \"accuracy is \", accuracy_score(y_test, y_pred)\n",
    "        print classification_report(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        print tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.967485549133\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      1309\n",
      "          1       0.84      0.49      0.62        75\n",
      "\n",
      "avg / total       0.96      0.97      0.96      1384\n",
      "\n",
      "1302 7 38 37\n",
      "('Best score for data1:', 0.96251548946716237)\n",
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "parameter_candidates = [\n",
    "  {'C': [0.1, 0.01, 1, 10, 100, 1000]}\n",
    "]\n",
    "model1 = LinearSVC()\n",
    "model_grid1 = GridSearchCV(model1, parameter_candidates)\n",
    "evaluateModel(model_grid1,X_train,y_train,X_test,y_test)\n",
    "print('Best score for data1:', model_grid1.best_score_)\n",
    "print model_grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.950867052023\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      1309\n",
      "          1       0.82      0.12      0.21        75\n",
      "\n",
      "avg / total       0.94      0.95      0.93      1384\n",
      "\n",
      "1307 2 66 9\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestClassifier()\n",
    "evaluateModel(model2,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score for data1:', 0.96189591078066916)\n"
     ]
    }
   ],
   "source": [
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "model_grid2 = GridSearchCV(SVC(),parameter_candidates)\n",
    "evaluateModel(model_grid2,X_train,y_train,X_test,y_test)\n",
    "print('Best score for data1:', model_grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.96098265896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      1309\n",
      "          1       0.80      0.37      0.51        75\n",
      "\n",
      "avg / total       0.96      0.96      0.95      1384\n",
      "\n",
      "1302 7 47 28\n"
     ]
    }
   ],
   "source": [
    "evaluateModel(model_grid2,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      1309\n",
      "          1       0.84      0.49      0.62        75\n",
      "\n",
      "avg / total       0.96      0.97      0.96      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967485549133\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1302    7]\n",
      " [  38   37]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1302, 7, 38, 37)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier(n_estimators=3000, max_depth=3, subsample=0.7, colsample_bytree= 0.7)\n",
    "gbm = gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99082292e-01,   8.85479835e-04,   3.22285569e-05],\n",
       "       [  9.99840524e-01,   1.46293847e-04,   1.31820306e-05],\n",
       "       [  9.99720408e-01,   2.74870572e-04,   4.72132789e-06],\n",
       "       ..., \n",
       "       [  9.97216883e-01,   2.45843813e-03,   3.24678593e-04],\n",
       "       [  9.99437219e-01,   4.98783467e-04,   6.39973732e-05],\n",
       "       [  9.99512944e-01,   4.63790575e-04,   2.32655399e-05]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result = []\n",
    "magic = 0.64\n",
    "for i in range(0, len(X_test)):\n",
    "    if y_pred[i][0] > magic:\n",
    "        y_result.append(0)\n",
    "    else:\n",
    "        y_result.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99240780911062909"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00       915\n",
      "        1.0       0.00      0.00      0.00         6\n",
      "        2.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.98      0.99      0.99       922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(y_test,y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('lgb',y_pred,delimiter = ',', fmt = '%0.6f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
